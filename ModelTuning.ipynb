{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import teleloggingbot\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, pearsonr, gmean\n",
    "import scipy as sp\n",
    "\n",
    "from sklearn.metrics import log_loss, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import xgboost\n",
    "import lightgbm as lgb\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Nadam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', 80) \n",
    "pd.set_option('display.max_rows', 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getKerasNN(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, init='he_uniform', input_dim=input_dim))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.15))\n",
    "#     model.add(Dense(64))\n",
    "#     model.add(Dropout(0.45))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1, activation='sigmoid', init='he_uniform'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=[])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfx_train = pd.read_csv('./x_train_my.csv', index_col=None)\n",
    "dfy_train = pd.read_csv('./y_train.csv', header=None)\n",
    "dfx_test =  pd.read_csv('./x_test_my.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.689114+1.12677e-05\ttest-logloss:0.689149+2.2069e-05\n",
      "[50]\ttrain-logloss:0.546864+0.000458823\ttest-logloss:0.548208+0.00100929\n",
      "[100]\ttrain-logloss:0.472392+0.000623091\ttest-logloss:0.474891+0.00156515\n",
      "[150]\ttrain-logloss:0.430901+0.000710238\ttest-logloss:0.434403+0.00201263\n",
      "[200]\ttrain-logloss:0.407021+0.000796862\ttest-logloss:0.41143+0.00235295\n",
      "[250]\ttrain-logloss:0.392986+0.000885477\ttest-logloss:0.398233+0.00262921\n",
      "[300]\ttrain-logloss:0.384629+0.000950277\ttest-logloss:0.390586+0.00288776\n",
      "[350]\ttrain-logloss:0.379535+0.000970087\ttest-logloss:0.386182+0.00310733\n",
      "[400]\ttrain-logloss:0.37637+0.000981235\ttest-logloss:0.383658+0.00323715\n",
      "[450]\ttrain-logloss:0.374254+0.000995089\ttest-logloss:0.382161+0.00344236\n",
      "[500]\ttrain-logloss:0.372802+0.00101555\ttest-logloss:0.38136+0.00357555\n",
      "[550]\ttrain-logloss:0.371694+0.00104418\ttest-logloss:0.380841+0.00367601\n",
      "[600]\ttrain-logloss:0.370754+0.00106128\ttest-logloss:0.380508+0.00371272\n",
      "[650]\ttrain-logloss:0.369928+0.00104402\ttest-logloss:0.380315+0.00378396\n",
      "[700]\ttrain-logloss:0.369149+0.00105465\ttest-logloss:0.380186+0.00381253\n",
      "[750]\ttrain-logloss:0.368426+0.00105285\ttest-logloss:0.380081+0.00387086\n",
      "[800]\ttrain-logloss:0.367717+0.00102044\ttest-logloss:0.380044+0.00388995\n",
      "[850]\ttrain-logloss:0.367045+0.00102896\ttest-logloss:0.37998+0.00387052\n",
      "[900]\ttrain-logloss:0.366407+0.00103098\ttest-logloss:0.37998+0.00387921\n",
      "[950]\ttrain-logloss:0.365823+0.00101985\ttest-logloss:0.379984+0.00387121\n",
      "Done.\n",
      "Done XGBOOST CV! logloss: 0.37995619999999997\n",
      "{   'colsample_bylevel': 0.85,\n",
      "    'colsample_bytree': 0.55,\n",
      "    'gamma': 3.3,\n",
      "    'learning_rate': 0.008,\n",
      "    'max_delta_step': 8.9,\n",
      "    'max_depth': 4,\n",
      "    'min_child_weight': 7.0,\n",
      "    'n_estimators': 920,\n",
      "    'nthread': 8,\n",
      "    'objective': 'binary:logistic',\n",
      "    'reg_lambda': 9.95,\n",
      "    'scale_pos_weight': 1.0,\n",
      "    'silent': 1,\n",
      "    'subsample': 0.55}\n",
      "CPU times: user 2min 11s, sys: 15.2 s, total: 2min 26s\n",
      "Wall time: 52.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_matrix = xgboost.DMatrix(dfx_train, dfy_train)\n",
    "xgb_param = {\n",
    "    'colsample_bylevel': 0.85,\n",
    "    'colsample_bytree': 0.55,\n",
    "    'gamma': 3.3,\n",
    "    'learning_rate': 0.008,\n",
    "    'max_delta_step': 8.9,\n",
    "    'max_depth': 4,\n",
    "    'min_child_weight': 7.0,\n",
    "    'n_estimators': 4000,\n",
    "    'nthread': 8,\n",
    "    'objective': 'binary:logistic',\n",
    "    'reg_lambda': 9.95,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.55\n",
    "}\n",
    "cvresult = xgboost.cv(xgb_param, xgb_matrix, num_boost_round=xgb_param['n_estimators']+1,\n",
    "                      nfold=5, verbose_eval=50, stratified=True, early_stopping_rounds=50,\n",
    "                      metrics='logloss', seed=42,)\n",
    "print('Done.')\n",
    "xgb_param['n_estimators'] = len(cvresult)\n",
    "msg = 'Done XGBOOST CV! logloss: {}\\n{}'.format(\n",
    "    cvresult['test-logloss-mean'].iloc[-1], pprint.pformat(xgb_param, indent=4))\n",
    "# teleloggingbot.sendMsg(msg) \n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(pd.concat((dfx_train, dfx_test)))\n",
    "xtrain = scaler.transform(dfx_train)\n",
    "xtest = scaler.transform(dfx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.378271050046\n",
      "2 0.389505603458\n",
      "3 0.38261223804\n",
      "4 0.381939568285\n",
      "5 0.381682689352\n",
      "MEAN: 0.3828 STD: 0.0036742\n",
      "Logloss on whole data 0.382802129042\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "scores = []\n",
    "error = np.zeros((len(dfy_train)), dtype=np.float32)\n",
    "\n",
    "batch_size = 512\n",
    "early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0,\n",
    "        patience=5,\n",
    "        verbose=0,\n",
    "        mode='auto')\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(xtrain, dfy_train.values.ravel())):\n",
    "    X_train, X_test = xtrain[train_index], xtrain[test_index]\n",
    "    y_train, y_test = dfy_train.values[train_index], dfy_train.values[test_index]\n",
    "    model = getKerasNN(dfx_train.shape[1])\n",
    "    model.fit(X_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=500,\n",
    "              verbose=0,\n",
    "              validation_split=0,\n",
    "              validation_data=(X_test, y_test),\n",
    "              callbacks=[early_stop])\n",
    "    preds = model.predict_proba(X_test, verbose=0)\n",
    "    error[test_index] = preds\n",
    "    scores.append(log_loss(y_test, preds))\n",
    "    print(i+1, scores[-1])\n",
    "print(\"MEAN: {:.5} STD: {:.5}\".format(np.mean(scores), np.std(scores)))\n",
    "print('Logloss on whole data', log_loss(dfy_train.values, error.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lgb_matrix = lgb.Dataset(dfx_train.values, dfy_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's binary_logloss: 0.50567\n",
      "[100]\tcv_agg's binary_logloss: 0.433182\n",
      "[150]\tcv_agg's binary_logloss: 0.402457\n",
      "[200]\tcv_agg's binary_logloss: 0.38925\n",
      "[250]\tcv_agg's binary_logloss: 0.383523\n",
      "[300]\tcv_agg's binary_logloss: 0.381175\n",
      "[350]\tcv_agg's binary_logloss: 0.380174\n",
      "[400]\tcv_agg's binary_logloss: 0.379842\n",
      "[450]\tcv_agg's binary_logloss: 0.379738\n",
      "[500]\tcv_agg's binary_logloss: 0.379737\n",
      "Done lightgbm CV! logloss: 0.37966813796021326 +- 0.00208693\n",
      "{   'bagging_fraction': 0.55,\n",
      "    'bagging_freq': 1,\n",
      "    'boosting': 'gbdt',\n",
      "    'feature_fraction': 0.75,\n",
      "    'lambda_l2': 6.05,\n",
      "    'learning_rate': 0.012,\n",
      "    'max_bin': 255,\n",
      "    'max_depth': 6,\n",
      "    'metric': ('binary_logloss',),\n",
      "    'num_iterations': 484,\n",
      "    'num_leaves': 15,\n",
      "    'num_threads': 8,\n",
      "    'objective': 'binary',\n",
      "    'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "lgb_param = {\n",
    "    'bagging_fraction': 0.55,\n",
    "    'bagging_freq': 1,\n",
    "    'boosting': 'gbdt',\n",
    "    'feature_fraction': 0.75,\n",
    "    'lambda_l2': 6.05,\n",
    "    'learning_rate': 0.012,\n",
    "    'max_bin': 31,\n",
    "    'max_depth': 6,\n",
    "    'metric': ('binary_logloss',),\n",
    "    'num_iterations': 1000,\n",
    "    'num_leaves': 15,\n",
    "    'num_threads': 8,\n",
    "    'objective': 'binary',\n",
    "    'verbose': 0\n",
    "}\n",
    "cvresult = lgb.cv(lgb_param, lgb_matrix, num_boost_round=lgb_param['num_iterations']+1,\n",
    "                  nfold=4, stratified=True, verbose_eval=50, early_stopping_rounds=50, show_stdv=False, seed=42)\n",
    "lgb_param['num_iterations'] = len(cvresult['binary_logloss-mean'])\n",
    "msg = 'Done lightgbm CV! logloss: {} +- {}\\n{}'.format(cvresult['binary_logloss-mean'][-1],\n",
    "                                                       round(cvresult['binary_logloss-stdv'][-1], 8),\n",
    "                                                       pprint.pformat(lgb_param, indent=4))\n",
    "# teleloggingbot.sendMsg(msg)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 336/3000 [09:55<1:15:53,  1.71s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_preds = []\n",
    "for i in tqdm(range(3000)):\n",
    "    s = i+1\n",
    "    np.random.seed(s)\n",
    "    random.seed(s)\n",
    "    random_param = lgb_param.copy()\n",
    "    random_param['seed'] = s+1\n",
    "    random_param['max_depth'] = np.random.choice([5,6,7], p=[0.6,0.2,0.2])\n",
    "    random_param['num_iterations'] += random.randint(-50,50)\n",
    "    lgb_clf = lgb.train(random_param, lgb_matrix, num_boost_round=random_param['num_iterations'])\n",
    "    lgb_preds.append(lgb_clf.predict(dfx_test.values))\n",
    "    \n",
    "teleloggingbot.sendMsg('DONE 3000 LGB!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_preds = []\n",
    "for i in tqdm(range(3000)):\n",
    "    s=i+1\n",
    "    np.random.seed(s)\n",
    "    random.seed(s)\n",
    "    random_param = xgb_param.copy()\n",
    "    random_param['seed'] = s\n",
    "    random_param['n_estimators'] += random.randint(-50, 50)\n",
    "    random_param['max_depth'] = np.random.choice([4,5,6], p=[0.6,0.2,0.2])\n",
    "    gbm = xgboost.XGBClassifier(**random_param)\n",
    "    gbm.fit(dfx_train, dfy_train.values.ravel())\n",
    "    xgb_preds.append(gbm.predict_proba(dfx_test)[:,1])\n",
    "teleloggingbot.sendMsg('DONE 3000 XGB!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [3:18:14<00:00,  3.79s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4h 40min 12s, sys: 4h 1min 58s, total: 8h 42min 11s\n",
      "Wall time: 3h 18min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlp_preds = []\n",
    "for i in tqdm(range(3000)):\n",
    "    s = i+1\n",
    "    np.random.seed(s)\n",
    "    random.seed(s)\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(64,64),\n",
    "                        batch_size=64\n",
    "                        learning_rate_init=0.01,\n",
    "                        max_iter=200+random.randint(-50,50),\n",
    "                        random_state=s)\n",
    "    clf.fit(dfx_train, dfy_train.values.ravel())\n",
    "    mlp_preds.append(clf.predict_proba(dfx_test)[:,1])\n",
    "teleloggingbot.sendMsg('DONE 5000 MLP!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"ans.csv\", gmean([\n",
    " gmean(lgb_preds),\n",
    " gmean(xgb_preds),\n",
    " gmean(mlp_preds)\n",
    "]), fmt='%10.16f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (mlenv)",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
